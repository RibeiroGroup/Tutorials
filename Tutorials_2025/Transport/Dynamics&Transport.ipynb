{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Quantum Dynamics and Energy Transport**\n",
        "\n",
        "\n",
        "\n",
        "**Motivation**: Systems with strong light-matter interactions (*polaritonic systems*) have been shown to enhance energy transport relative to the purely excitonic case, meaning faster and more efficient energy transfer for a whole host of technological applications. To fully take advantage of this phenomenon, we must understand the physics of these systems and each parameter that contributes to it.\n",
        "\n",
        "This means creating a model for a system of interest and running dynamics simulations varying the parameters to understand how changes to the system affect the total energy transport. This will allow us to determine how to maximize (or minimize) the transport properties of these novel systems, giving design principles for future polaritonic devices.\n",
        "\n",
        "\n",
        "> **Goal:** To understand and learn to code a *Quantum Dynamics Simulation* and extract *energy transport* properties. We are interested in particular in the dynamics of a Polaritonic System, a system with strong light-matter interactions that has been shown to enhance enhance energy transport, both with and without disorder.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UCzfccJUJDcH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Introduction to Quantum Dynamics ##\n",
        "\n",
        "### 1.1 Building the Hamiltonian Matrix ###\n",
        "\n",
        "In the last tutorial, we talked about building the Hamiltonian matrix for a few simplified models for understanding polaritons (*the Jaynes-Cummings and Tavis_Cummings models*). We are going to take a more general route here to look at the basics of energy transport.\n",
        "\n",
        "To build the Hamiltonian matrix, we must first start with some intuition about the physical system we are representing. For a basic picture of energy transport, let us assume that we are dealing with a linear chain of molecules (1D) that are aligned along the $x$ direction with some position $x_n$, and that each molecule is a two level system with a ground $|0\\rangle$ and excited $|1\\rangle$ state separated by energy $E_m$.\n",
        "\n",
        "A convenient basis to work in for this example is the **position basis**, meaning that it will be easy to represent the intial state of our system as a linear combination of our molecular positions (or sites), and that this basis will let us understand where the excitation is and how it is propagating. We can represent our initial state as follows:\n",
        "\\begin{align*}\n",
        "    |\\psi_0\\rangle = \\sum_n^{N_M} |x_n\\rangle \\langle x_n| \\psi_0\\rangle = \\sum_n^{N_M} c_n |x_n\\rangle\n",
        "\\end{align*}\n",
        "\n",
        "where $N_M$ is the total number of molecules in our system and we have just resolved $|\\psi_0\\rangle$ in the position basis.\n",
        "\n",
        "\n",
        "\n",
        "For simplicity, let us keep our system restrained to the single excitation manifold, meaning that only one molecule can be excited at once. Since we are interested in energy transport, we will use the site basis, giving our wave function in terms of the basis where one molecule is excited and the rest are in the ground state. We will represent that as\n",
        "\n",
        "\\begin{align*}\n",
        "    |\\psi_0\\rangle = \\sum_n^{N_M} |1_n\\rangle \\langle 1_n| \\psi_0\\rangle = \\sum_n^{N_M} c_n |1_n\\rangle\n",
        "\\end{align*}\n",
        "\n",
        "where $|1_n\\rangle$ is the state where the $n$th molecule is excited and all other are in the ground state. $c_n$ is then the amplitude correlated to the probability of finding site $n$ in the excited state.\n",
        "\n",
        "\n",
        "We will now consider what a **Hamiltonian** for this system will look like.\n",
        "\n",
        "Let us consider first that each site has energy $E_m$. This means that we know the diagonal matrix elements for the Hamiltonian already.\n",
        "\n",
        "\n",
        "\\begin{align*}\n",
        "    \\langle 1_n | \\hat{H} | 1_n \\rangle = E_m.\n",
        "\\end{align*}\n",
        "\n",
        "or equivalently\n",
        "\n",
        "\\begin{align*}\n",
        "    \\hat{H}_{diag} = \\sum_n^{N_M} E_m |1_n\\rangle \\langle 1_n|\n",
        "\\end{align*}\n",
        "\n",
        "\n",
        "Let us assume that the molecular excitation (or exciton) has some probability of giving energy to other sites. We will represent this as a \"hopping amplitude\" $J$. Let us restrict the hopping to only hop between nearest neighbors, meaning amplitude can transfer from site $n$ to site $n+1$ and $n-1$ only.\n",
        "\n",
        "To write the full Hamiltonian, we must include the diagonal piece, as well as all other interactions. Luckily for us, this \"nearest neighbor coupling\" means that we can easily write down the rest of the matrix elements. We know that there is no coupling between sites that are more than one site away, meaning that the matrix elements of the Hamiltonian that connect sites greater than one site away will be zero. And the nearest neighbor sites will couple with the hopping amplitude $J$. The full Hamiltonian becomes\n",
        "\n",
        "\\begin{align*}\n",
        "    \\hat{H} = \\sum_n^{N_M} E_m |1_n\\rangle \\langle 1_n| + J( |1_{n+1} \\rangle \\langle 1_n| + |1_{n}\\rangle \\langle 1_{n+1}| )\n",
        "\\end{align*}\n",
        "\n",
        "or\n",
        "\n",
        "\\begin{align*}\n",
        "    \\hat{H} = \\sum_n^{N_M} E_m \\hat{b}^â€ _n\\hat{b}_n + J( \\hat{b}^\\dagger_{n+1} \\hat{b}_n + \\hat{b}^\\dagger_{n} \\hat{b}_{n+1} )\n",
        "\\end{align*}\n",
        "\n",
        "> If this notation is unfamiliar to you, please look back at the last tutorial where it goes over *creation* and *annihilation* operators.\n",
        "\n",
        "### **Task:** ###\n",
        "\n",
        "Write a function that takes in the parameters $Em$, $N_M$, and $J$ and generates this simple Hamiltonian.\n"
      ],
      "metadata": {
        "id": "e1majj7GKLHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Hamiltonian Marix: You can write in either the Python or Julia coding language\n",
        "\n",
        "def build_H(Em, Nm, J)      # <-- Python\n",
        "\n",
        "### your code here ###\n",
        "######################\n",
        "######################\n",
        "\n",
        "function build_H(Em, Nm, J)      # <-- Julia\n",
        "\n",
        "### your code here ###\n",
        "######################\n",
        "######################\n",
        "end"
      ],
      "metadata": {
        "id": "fUymOlIPKKAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Time-Independent SchrÃ¶dinger Equation ###\n",
        "\n",
        "One of the principle equations of quantum mechanics is the **SchrÃ¶dinger Equation**, which defines the energy levels and energy eigenfunctions that can be used to describe any wave function of a system. There are two variations of the SchrÃ¶dinger equation, the time-independent and the time-dependent equation.\n",
        "\n",
        "The time-independent SchrÃ¶dinger equation (TISE) is given as follows:\n",
        "\n",
        "\\begin{align*}\n",
        "    \\hat{H} |\\phi_i \\rangle = E_i |\\phi_i \\rangle\n",
        "\\end{align*}\n",
        "\n",
        "Each solution to this equation $|\\psi_i \\rangle$ is an eigenfunction of the Hamiltonian associated with the energy $E_i$. The eigenvectors $|\\psi_i\\rangle$ satisfy the property\n",
        "\n",
        "\\begin{align*}\n",
        "    \\langle\\phi_i | \\phi_j \\rangle = \\delta_{ij}\n",
        "\\end{align*}\n",
        "\n",
        "where $\\delta_{ij}$ is the Kronecker delta.\n",
        "\n",
        "\n",
        "This means that the eigenvectors $|\\psi_i\\rangle$ are **orthonormal**, meaning there is no overlap between (or the inner product is zero for) different states, and that each state is itself normalized (the inner product with itself is one).\n",
        "\n",
        "> **Note:** This is similar to the orthogonal unit vectors that point in the $x$, $y$, and $z$ directions ($\\hat{i}$, $\\hat{j}$, and $\\hat{k}$ respectively). The inner product (or dot product) between each of those vectors is zero unless it is dotted with itself, in which case it is one. One can represent this using\n",
        "> \\begin{align*}\n",
        "     x_i \\cdot x_j &= \\delta_{ij}  \n",
        "\\end{align*} where i,j are components along the unit vectors $\\hat{i}$, $\\hat{j}$, and $\\hat{k}$.\n",
        "\n",
        "\n",
        "Since these energy eigenvectors form an orthonormal set, they form a good **basis** to represent your wave function. We can do this by performing the same resolution of the identity that we showed before for putting our intial state into the position basis, only using our eigenvectors as a basis instead of the site basis we have been using.\n",
        "\n",
        "\\begin{align*}\n",
        "    |\\alpha\\rangle = \\sum_j |\\phi_j\\rangle \\langle \\phi_j | \\alpha\\rangle = \\sum_j c_j |\\phi_j\\rangle\n",
        "\\end{align*}\n",
        "\n",
        "where $|\\alpha\\rangle$ is a generic wave function.\n",
        "\n",
        "\n",
        "To get the eigenvectors and eigenvalues of the Hamiltonian, you must set up the matrix equation that diagonalizes $\\hat{H}$ to find the eigenvalues and eigenvectors:\n",
        "\n",
        "\\begin{align*}\n",
        "    \\hat{H} &= \\Phi^{-1} Î› \\Phi = \\Phi^\\dagger Î› \\Phi \\\\\n",
        "\\end{align*}\n",
        "\n",
        "where $\\Phi$ is the matrix that diagonalizes $\\hat{H}$ to give the diagonal matrix of eigenvalues $Î›$. $\\Phi$ then is the matrix where the columns correspond to the eigenvectors.\n",
        "\n",
        "This set of eigenvectors and the corresponding eigenvalues will automatically satisfy the TISE, giving the energies and their eigenstates.\n",
        "\n",
        "The eigenvalue problem is a simple linear algebra problem, and to solve for $\\Phi$ and $\\Lambda$ one must solve\n",
        "\n",
        "\\begin{align*}\n",
        "    \\hat{H} |\\phi \\rangle = \\lambda |\\phi\\rangle \\\\ \\implies | \\hat{H} - \\lambda ðˆ | = 0\n",
        "\\end{align*}\n",
        "\n",
        "giving the characteristic equation.\n",
        "\n",
        "Luckily for us, there are easy routines already written in Python and Julia that can take care of this diagonalization for us.\n",
        "\n",
        "\n",
        "### **Task:**\n",
        "\n",
        "- Take the Hamiltonian matrix that you have constructed and diagonalize it and print out the eigenvalues and the eigenvectors.\n",
        "\n",
        "- Ensure that the matrix of eigenvectors transforms the Hamiltonian into a diagonal matrix (use the eigenvectors to explicitly transform $\\hat{H}$ into a diagonal matrix). The resulting matrix should have the eigenvalues along the diagonal and zeros for every other entry.\n"
      ],
      "metadata": {
        "id": "rx0CHChLdCZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Write your code here! ###\n",
        "\n",
        "print(evals)\n",
        "print(evecs)\n",
        "\n",
        "# Perform matrix multiplication\n",
        "\n",
        "\n",
        "# Check to see that resulting diagonal matrix gives the eigenvalues\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZtD4Is058wr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Time-Dependent SchrÃ¶dinger Equation and the Time-Evolution Operator ###\n",
        "\n",
        "Now that we know our Hamiltonian, and have our energy states (eigenvectors), we can begin to discuss quantum dynamics.\n",
        "\n",
        "We have talked about the stationary state solutions to the TISE (energy eigenstates), but there is another form of the SchrÃ¶dinger equation that dictates how a system changes over time. That equation is the **time-dependent SchrÃ¶dinger equation** (TDSE).\n",
        "\n",
        "\\begin{align*}\n",
        "    i Ä§ \\frac{âˆ‚}{âˆ‚t} |\\psi\\rangle = \\hat{H} |\\psi\\rangle\n",
        "\\end{align*}\n",
        "\n",
        "This tells us that it is the Hamiltonian operator that dictates how a system changes over time. From this, we can determine the **time-evolution operator** $\\hat{U}(t,t_0)$ that satisfies\n",
        "\n",
        "\\begin{align*}\n",
        "    |\\psi(t)\\rangle = \\hat{U}(t,t_0) |\\psi(t_0)\\rangle\n",
        "\\end{align*}\n",
        "\n",
        "The time-evolution operator takes the form:\n",
        "\n",
        "\n",
        "\\begin{align*}\n",
        "    \\hat{U}(t,t_0) = e^{-i \\hat{H}(t-t_0) / \\hbar}\n",
        "\\end{align*}\n",
        "\n",
        ">**Optional Exercise:** show that going from the TDSE one can arrive at this form for the time-evolution operator. This can be helpful in seeing where this operator comes from.\n",
        "\n",
        "Therefore, if we know the intial state wave function for a system, and we know the Hamiltonian, we can construct the time-evolution operator and generate the wave function of the system at any time $t$. *This is how we understand quantum dynamics.*\n",
        "\n",
        "\n",
        "### **Question:** ###\n",
        "\n",
        "How can we construct this time-evolution operator given our Hamiltonian? You can attempt to write code to do this below."
      ],
      "metadata": {
        "id": "nnBdYRtibfpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Time-Evolution Operator #\n",
        "\n",
        "def build_U(?,?,?)\n",
        "\n",
        "### You can put your code here ###"
      ],
      "metadata": {
        "id": "ueU2SQoxJ8jQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **If you are having trouble creating this operator, please know you are in good company!** ###\n",
        "\n",
        "It turns out, $\\hat{U}(t,t_0)$ is an exponential of a matrix ($\\hat{H}$), which can be tricky. Yes, you can write a routine that performs this matrix exponential (because exponentials are defined through a Taylor expantion), but each successive term is a higher order of matrix multiplication (which is a lot of operations!).\n",
        "\n",
        "Even optimized forms for a matrix exponential operation ($e^{\\hat{A}}$) that can be called from Julia or Python libraries can only be used for very small systems due to the large number of operations required and the computing time, making this very un-friendly to work with.\n",
        "\n",
        "***So what can we do?***\n",
        "\n",
        "As mentioned earlier, exponential functions can be defined through a Taylor series expansion:\n",
        "\n",
        "\\begin{align*}\n",
        "    e^x = \\sum_{n=0}^âˆž \\frac{x^n}{n!} = 1+x +\\frac{x^2}{2!} + \\frac{x^3}{3!}+ ...\n",
        "\\end{align*}\n",
        "\n",
        "so the time-evolution operator expanded in its Taylor series is\n",
        "\n",
        "\\begin{align*}\n",
        "    \\hat{U}(t,t_0) &=  e^{-i \\hat{H}(t-t_0) / \\hbar} = \\sum_{n=0}^âˆž \\left( \\frac{-i(t-t_0)}{\\hbar} \\right)^n \\frac{(\\hat{H})^n}{n!}  \\\\ &= 1 -\\frac{i}{\\hbar} \\hat{H}(t-t_0) - \\frac{1}{2\\hbar^2} \\hat{H}^2 (t-t_0)^2 + \\frac{i}{6\\hbar^3} \\hat{H}^3 (t-t_0)^3 + ...\n",
        "\\end{align*}\n",
        "\n",
        "where one can see that each term in the expansion is some order of the Hamiltonian, from zeroth order ($\\hat{H}^0 = 1$) to higher order terms ($\\hat{H}^3 = \\hat{H} \\hat{H} \\hat{H}$} multiplied by some coefficient. This does not immediately simplify the problem, as we have just defined our operator in a different way, as we would still have to compute the action of $\\hat{H}$ on our wave function $|\\psi \\rangle$, and then compute the action of $\\hat{H}$ on the resulting wave function, etc.\n",
        "\n",
        "However, we do know the action of $\\hat{H}$ on its **eigenstates**, $|\\phi_j \\rangle$: $\\hat{H} |\\phi_j \\rangle = E_j |\\phi_j \\rangle$. Since it is an eigenstate, repeated application of the Hamiltonian on $|\\phi_j \\rangle$ will only multiply the state by its eigenvale, $E_i$, meaning\n",
        "\n",
        "\\begin{align*}\n",
        "    \\hat{H}^n |\\phi_j \\rangle = E^n_j |\\phi_j \\rangle.\n",
        "\\end{align*}\n",
        "\n",
        "This allows us to write our time-evolution operator as\n",
        "\n",
        "\\begin{align*}\n",
        "    \\hat{U}(t,t_0) = e^{-i E_j (t-t_0) / \\hbar}\n",
        "\\end{align*}\n",
        "\n",
        " when acting on the eigenstates, which greatly reduces the complexity, as everything in the exponential is a scalar. This is a large improvement on matrix multiplication!\n",
        "\n",
        "\n",
        "\n",
        " ******\n",
        " **Utilizing the Eigenvectors**\n",
        "\n",
        "  As mentioned before, since our eigenstates form a good, orthonormal basis, we can represent any state in terms of the eigenstates.\n",
        "\n",
        "  \\begin{align*}\n",
        "    |\\alpha\\rangle = \\sum_j |\\phi_j\\rangle \\langle \\phi_j | \\alpha\\rangle = \\sum_j c_j |\\phi_j\\rangle\n",
        "\\end{align*}\n",
        "\n",
        "The important quantity to compute then, is $\\langle \\phi_j | \\alpha \\rangle$ for every eigenvector $|\\phi_j \\rangle$. This is just the inner product of the generic wave function $|\\alpha \\rangle$ and the (complex conjugate of the) $j$th energy eigenvector. This is often called computing the \"overlap\" of the $j$th eigenvector with $|\\alpha \\rangle$, and gives the projection of $|\\alpha \\rangle$ on $|\\phi_j\\rangle$.\n",
        "\n",
        "> **Note:** An analogous way to view this is with a 3D vector in real space. In this analogy, the wave function could be any vector pointing in any direction. Computing the overlap of the \"wave function\" vector with the Cartesian coordinates ($x$, $y$, and $z$), for instance, would be projecting that vector onto each axis to see how much of the vector points along each coordinate direction, or basis vector. Since we know that the coordinate basis vectors are unit length, we know that this projection is just the dot product, or inner product, of our original vector and the $x$, $y$, and $z$ basis vectors. So any vector can be represented in the Cartesian coordinate basis by computing the overlaps with each basis vector: $|u\\rangle = \\langle x | u \\rangle |x\\rangle + \\langle y | u \\rangle |y\\rangle + \\langle z | u \\rangle |z\\rangle$ or $[\\langle x | u \\rangle, \\langle y | u \\rangle, \\langle z | u \\rangle]^T$ given in the $x$, $y$, $z$ basis.\n",
        "\n",
        "In the Dirac Bra-Ket notation, we know that a \"Bra\" vector is a row vector that is the complex conjugate of the corresponding \"Ket\" column vector. So to transform our wave function state into the eigenstate basis, we must compute the overlap of the wave function state with each of the eigenvectors, and that will give us our wave function written in the eigenstate basis.\n",
        "\n",
        "****\n",
        "**Task:**\n",
        "- Assuming that the state is given as a linear combination of the eigenstates, write a function for time-evolving a state from some initial time $t_0$ to some time $t$.\n",
        "\n",
        "- As arguments you will need to take at least in the vector representing the intial state (must be in the eigenstate basis for evolution), the vector of eigenvalues, and the time you are evolving to."
      ],
      "metadata": {
        "id": "xyVnmEIDECAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def time_evol( )\n",
        "\n",
        "hbar = 0.0006582119569509067     # Reduced Planck's Constant in eV*ps\n",
        "\n",
        "###################\n",
        "# Your code here! #\n",
        "###################\n",
        "\n",
        "return psi_t"
      ],
      "metadata": {
        "id": "jb1EBn44OatZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 Initial State\n",
        "\n",
        "Since we now know how to propagate our wave function through time using the time-evolution operator, we must now decide what our initial state wave function will be. In general, one can choose any intial state and propagate it through time with the Hamiltonian to examine the dynamics, but in our case, we are interested in the ***energy transport***, meaning we are interested in knowing how the energy or an excitation spreads from one molecule to others. For this kind of simulation, we will focus on an intial state that is relatively localised on a few molecules, and see how it will spread in time.\n",
        "\n",
        "Let us remain focused on the one-dimensional chain of molecules that we discussed when building our Hamiltonian.\n",
        "****\n",
        "**Task:**\n",
        "\n",
        "Using the same basis (local, or site basis) that we used to build our original Hamiltonian, build an initial state wave function for a chain of $N_M$ molecules that have spacing $a$ nm from each other that is given as a Gaussian distribution centered in the middle of the chain.\n",
        "\n",
        "recall that a Gaussian is given by\n",
        "\n",
        "\\begin{align*}\n",
        "    f(x) =\\frac{1}{Z} e^\\frac{-(x-x_0)^2}{2\\sigma^2}\n",
        "\\end{align*}\n",
        "\n",
        "where **$Z$** is the normalization factor, **$x_0$** is the center of the gaussian, and **$\\sigma$** is the standard deviation, or the width, of the gaussian.\n",
        "\n",
        "> *Hint:*\n",
        "> - the Gaussian distribution will be the coefficient of each site based on the position of each site.\n",
        "> - think about what $x$ is for each site\n",
        "> - don't worry about the normalization constant until the end; you will need to ensure normalization at that point anyway.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5LPUleb9D66V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Write code to build the initial state as described ###\n",
        "\n",
        "# Inputs:\n",
        "Nm = ###\n",
        "a = ###\n",
        "sigma_x = ###\n",
        "\n",
        "\"\"\" Python \"\"\"\n",
        "def build_psi(Nm, a, sigma_x)\n",
        "\n",
        "# Your code here!\n",
        "#\n",
        "#\n",
        "\n",
        "\n",
        "------------------------------\n",
        "\n",
        "\n",
        "\"\"\" Julia \"\"\"\n",
        "function build_psi(Nm, a, sigma_x)\n",
        "\n",
        "# Your code here!\n",
        "#\n",
        "#\n",
        "\n",
        "end\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-5MZQY5yJL4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Plot your initial state as a function of the molecular index to ensure that it is a Gaussian centered where you want it (the center of the chain)\n",
        "- Plot the probabilities for each site to be excited\n",
        "- Check to make sure that it is normalized $\\langle \\psi_0 | \\psi_0 \\rangle = 1$"
      ],
      "metadata": {
        "id": "jQN1F-qnIvR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot initial state\n",
        "plot(n, psi_0) # n = molecular index\n",
        "\n",
        "# Plot the probabilities of the initial state\n",
        "plot(n, prob_psi_0)\n",
        "\n",
        "# Check normalization\n",
        "# |psi_0|^2 == 1"
      ],
      "metadata": {
        "id": "R5aHjQ2gJxi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Dynamics Simulation\n",
        "\n",
        "\n",
        "Now we have all of the pieces to run a quantum dynamics simulation. Below is a general framework for performing this kind of dynamics simulation:\n",
        "\n",
        "****\n",
        "\n",
        "> 1. Build an effective Hamiltonian to model your system of interest\n",
        "> 2. Create your initial state\n",
        "> 3. Diagonalize your Hamiltonian to determine eigenvalues (energies) and eigenvectors\n",
        "> 4. Convert your initial state into the eigenstate basis\n",
        "> 5. Propagate the initial state using the time-evolution operator (be sure to use the correct form of $\\hat{U}(t,t_0)$ when in the eigenbasis!)\n",
        "> 6. Convert back into the local basis (if you are looking at some observable)\n",
        "\n",
        "****\n",
        "### 2.1 Tracking Excitation Probabilities\n",
        "\n",
        "\n",
        "**Task:**\n",
        "\n",
        "Write a function that performs all of these functions together to run a dynamics simulation for the system that we have been discussing. Have your function save the probabilities for each site at each time step. You can do this efficiently by creating a matrix to store your results that is $N_M$x length(tvals) *(variables defined below)* and at each time step computing the excitation probability of each site and write them as a column in the matrix corresponding to the time.\n",
        "\n",
        "> *Hint:*\n",
        "You will need to create a loop through time and repeat steps 4-6 for each value of time, and compute the probabilities for each site after converting into the local basis before looping back to step 4."
      ],
      "metadata": {
        "id": "fYk6NpmWKT1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" This funciton must take in the following arguments:\n",
        "\n",
        "Nm = # total number of molecules\n",
        "a = # distance between molecules (nm)\n",
        "sigma_x = # initial width of the wave packet in real space (nm)\n",
        "Em = # excitation energy of the molecules (eV)\n",
        "J = # coupling parameter (eV)\n",
        "tvals = # a vector of time values for the times evolving through (ps)\n",
        "\n",
        " ^ this can be a singular number, but it will be more illustrative of the dynamics if it is a vector with many\n",
        "   times with a small time step so that you can see how the system is changing. For that reason, I suggest going\n",
        "   ahead and writing your code to take in a vector of time values\n",
        "\n",
        " Note the units in the above arguments. These can be arbitrary units, but the units must match for hbar (which I gave\n",
        " to you in ev*ps, but you may use other units)\n",
        "\"\"\"\n",
        "\n",
        "# Python #\n",
        "\n",
        "def dynamics_sim(Nm, a, sigma_x, Em, J, tvals)\n",
        "\n",
        "### Your code here! ###\n",
        "\n",
        "return prob_t # Probabilities as a function of time.\n",
        "\n",
        "----------------------------------------------------\n",
        "\n",
        "# Julia #\n",
        "\n",
        "function dynamics_sim(Nm, a, sigma_x, Em, J, tvals)\n",
        "\n",
        "  ### Your code here! ###\n",
        "\n",
        "  return prob_t # Probabilities as a function of time.\n",
        "end\n"
      ],
      "metadata": {
        "id": "UpAlBoPeHhz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Now make an animation of these probabilities to make sure that the initial wave packet is moving as expected. If not, you may have some issues with your code (or units)!\n",
        "> Use an animation strategy similar to the following example written in Julia (feel free to get your preferred AI overlord to translate it into Python if you would rather work in Python):"
      ],
      "metadata": {
        "id": "mtRIW_rHT-MD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of frames in Animation\n",
        "nframes = size(wvpkt, 2) # \"wvpkt\" here will be \"prob_t\" in the above example; Nm x length(tvals) matrix\n",
        "\n",
        "ymin, ymax = extrema(wvpkt)\n",
        "\n",
        "timevalues = [0.0, 0.02, 0.04, ...] # use your actual \"tvals\" vector\n",
        "\n",
        "# Create the Animation\n",
        "anim = @animate for i in 1:nframes\n",
        "    plot(1:Nm, wvpkt[:,i], xlabel=\"Molecular Site\", ylabel=\"Excitonic Probability\", title=\"Ï„ = 40 fs\", legend=false)\n",
        "    annotate!(fld(Nm,2), 0.5*ymax - 0.1*(0.5*ymax-ymin), text(\"t = $(timevalues[i]) ps\", :center, 12))\n",
        "end\n",
        "\n",
        "# Save the animation as a gif (you can adjust fps as needed)\n",
        "gif(anim, \"Probabilities.gif\", fps = 2)"
      ],
      "metadata": {
        "id": "f366qyq6VHIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Your animatation code here! ###\n",
        "\n",
        "display(anim)"
      ],
      "metadata": {
        "id": "OLpO5SGTYbw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Questions:***\n",
        "- Does the excitation wave packet move as expected?\n",
        "- What happens if $J = 0$? If you increase $J$?\n",
        "- What if we begin with a smaller/larger $\\sigma_x$? How does that change the dynamics? Why?"
      ],
      "metadata": {
        "id": "PJccSGO3YPaX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Quantifying Energy Transport\n",
        "\n",
        "Once you know your code functions properly for time-evolving a system and you can see that the wave packet is in fact spreading, we now need to quantify the spread. One way we do this is by tracking the root mean squared displacement (RMSD). The RMSD is calculated in the following way:\n",
        "\n",
        "\\begin{align*}\n",
        "    \\langle x^2(t) \\rangle = \\frac{1}{P(t)} \\sum_n^{N_M} |C_n|^2 (x_n - x_0)^2\n",
        "\\end{align*}\n",
        "\n",
        "where $P(t) = \\sum_n^{N_M}|C_n|^2$ is the total probability (which should sum to 1, if everything is normalized), and $C_n$ is the amplitude for having an excitation on site $n$.\n",
        "\n",
        "****\n",
        "\n",
        "**Task:**\n",
        "- Write a function that will calculate the RMSD of a wave function at a certain time given the wave function ($\\psi$), the total number of molecules ($N_M$), and the spacing between the molecules ($a$)."
      ],
      "metadata": {
        "id": "PDQRDpLtYmfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_RMSD(psi, Nm, a)\n",
        "\n",
        "###################\n",
        "# Your code here! #\n",
        "###################\n",
        "\n",
        "return rmsd_val"
      ],
      "metadata": {
        "id": "r9wwlSTEdYux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Now modify the function you wrote to create the system and time-evolve it (**2.1**) to instead compute the RMSD for every time step and return just the vector storing the RMSD values computed at each time step.\n",
        "\n",
        "> *Hint:*   \n",
        "Be sure that you compute the RMSD when the wave function is given in the site (local) basis! If you do this in the eigenbasis it will not make any sense!\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zyvjKiTldpJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dynamics_sim_rmsd( ?????? )\n",
        "\n",
        "###################\n",
        "# Your code here! #\n",
        "###################\n",
        "\n",
        "return rmsd_vals"
      ],
      "metadata": {
        "id": "yImrC9SDeWrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Run this simulation and plot the RMSD vs time to see how the wave packet spreads. You can compare this to the animation you made earlier.\n"
      ],
      "metadata": {
        "id": "Ij5d9glPet_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot(tvals, rmsd_vals)"
      ],
      "metadata": {
        "id": "7ysyKtvCfMpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- What does this graph look like? What happens when you tweak the parameters such as $J$, $\\sigma_x$, and $a$? Can you explain why this changes the RMSD?"
      ],
      "metadata": {
        "id": "sFQWa5KUfQlj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Further Explorations\n",
        "\n",
        "You have now learned the basics of quantum dynamics, and have successfully coded and ran a basic quantum dynamics simulation.\n",
        "\n",
        "Using the framework and the tools you learned here, you will be able to probe more interesting systems, such as the **polaritonic systems** that we in the Ribeiro lab are studying.\n",
        "\n",
        "### 3.1 More Complicated Systems\n",
        "\n",
        "One of the critiques of these kinds of simulations is their underlying assumptions, such as the case that we have been dealing with, where every molecule had the exact same excitation energy. We know this is not true, as the spectrum of every material has a non-zero linewidth. The presence of some linewidth in a molecular spectrum indicates that there is *energetic disorder* in the sample, meaning that there is a distribution of excitation energies. One attempt to take our simple model further is to implement disorder in the molecular energies.\n",
        "\n",
        "***Exercises to continue exploration:***\n",
        "\n",
        "(*Optional*)\n",
        "- How can we implement disorder into the system that we have been investigating?\n",
        "- What will that do to the dynamics of our system?\n",
        "- What happens when there is disorder in the spacing $a$ of the molecules, where some molecules are closer or farther away from their neighbors? How can we account for this?\n",
        "- Adjust your previous code to incorporate energetic disorder into the model. Do this with the molecular spacing as well.\n",
        "- In a previous tutorial, we have given a model Hamiltonian for a polaritonic system. How can we adjust our code to simulate the dynamics of a polaritonic system? What different parameters could we adjust there?\n"
      ],
      "metadata": {
        "id": "W3T6P3pyiAYK"
      }
    }
  ]
}